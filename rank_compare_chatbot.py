import streamlit as st
import pandas as pd
import os
import json
import re
from datetime import datetime
from dotenv import load_dotenv
from utils import load_dataframes, plot_bar_chart_plotly
from openai import OpenAI

# âœ… í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° API í‚¤ ì„¤ì •
load_dotenv()
client = OpenAI()

# âœ… ë°ì´í„° ë¡œë“œ
data_dir = os.path.dirname(__file__)
dfs = load_dataframes(data_dir)

# âœ… GPT ê¸°ë°˜ ì§ˆë¬¸ íŒŒì‹± í•¨ìˆ˜ (OpenAI ìµœì‹  ë²„ì „ í˜¸í™˜)
def parse_natural_query_with_gpt(query):
    gpt_prompt = f'''
    ë‹¤ìŒ ì§ˆë¬¸ì„ JSON í˜•ì‹ìœ¼ë¡œ êµ¬ì¡°í™”í•´ì¤˜.
    - years: [2023, 2024] í˜•íƒœë¡œ ì¶”ì¶œ
    - product: ECM, ABS, FB, êµ­ë‚´ì±„ê¶Œ ì¤‘ í•˜ë‚˜
    - company: ì¦ê¶Œì‚¬ ì´ë¦„
    - columns: ê¸ˆì•¡, ê±´ìˆ˜, ì ìœ ìœ¨ ì¤‘ í¬í•¨ëœ ë¦¬ìŠ¤íŠ¸
    - is_chart: true/false
    - is_top, is_compare, rank_range, top_n ë“±ì˜ ì¶”ê°€ ì •ë³´ í¬í•¨

    ì§ˆë¬¸: {query}
    ê²°ê³¼ëŠ” JSONë§Œ ì¤˜.
    ì˜ˆì‹œ:
    {{
      "years": [2023, 2024],
      "product": "ECM",
      "company": "ë¯¸ë˜ì—ì…‹ì¦ê¶Œ",
      "columns": ["ê¸ˆì•¡(ì›)", "ê±´ìˆ˜"],
      "top_n": 5,
      "rank_range": [1,5],
      "is_chart": true,
      "is_compare": false,
      "is_top": false
    }}
    '''
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” ê¸ˆìœµ ë¦¬ê·¸í…Œì´ë¸” ì§ˆë¬¸ì„ ë¶„ì„í•˜ëŠ” íŒŒì„œì•¼."},
                {"role": "user", "content": gpt_prompt}
            ]
        )
        result_text = response.choices[0].message.content.strip()
        if not result_text:
            st.error("GPT ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return None
        st.text("ğŸ“¤ GPT ì‘ë‹µ:")
        st.code(result_text)
        try:
            json_start = result_text.find('{')
            json_end = result_text.rfind('}') + 1
            result_text = result_text[json_start:json_end]
            return json.loads(result_text)
        except json.decoder.JSONDecodeError:
            st.error(f"GPT ì‘ë‹µì„ JSONìœ¼ë¡œ íŒŒì‹±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n{result_text}")
            return None
    except Exception as e:
        st.error(f"GPT í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        import traceback
        st.text(traceback.format_exc())
        return None
